{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(\"../../Data/cleaned_v2.csv\")[\"Content_cleaned_v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61106"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "x = \" \".join(docs).split()\n",
    "for i in x:\n",
    "  if i in dic:\n",
    "    dic[i] += 1\n",
    "  else:\n",
    "    dic[i] = 1\n",
    "len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [doc.split() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22187"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(test, min_count=1, workers= 2, vector_size= 256, window= 9, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.save(\"w2v_256_skip_cleaned_v2_v2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61106 61106\n"
     ]
    }
   ],
   "source": [
    "vocabs = list(w2v.wv.key_to_index)\n",
    "vects = list(w2v.wv.vectors)\n",
    "# Print the first 10 words in the vocabulary\n",
    "print(len(vocabs), len(vects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('siêng_năng', 0.6941134929656982),\n",
       " ('cần_mẫn', 0.6356588006019592),\n",
       " ('linh_quân', 0.6303225159645081),\n",
       " ('chí_anh', 0.6291424632072449),\n",
       " ('bảo_tiên', 0.6275516152381897),\n",
       " ('tiến_thủ', 0.6127573847770691),\n",
       " ('giỏi_giang', 0.605018675327301),\n",
       " ('khổ_luyện', 0.6022093892097473),\n",
       " ('năm_học_tập', 0.5966137051582336),\n",
       " ('thỏa_niềm', 0.5964890122413635)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(\"chăm_chỉ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# out_v = io.open(\"vecs_cbow.tsv\", \"w\", encoding=\"utf-8\")\n",
    "# out_m = io.open(\"meta_cbow.tsv\", \"w\", encoding=\"utf-8\")\n",
    "# for i in range(1, len(vocabs)):\n",
    "#   word = vocabs[i]\n",
    "#   vector = vects[i]\n",
    "#   out_m.write(word + \"\\n\")\n",
    "#   out_v.write(\"\\t\".join([str(x) for x in vector]) + \"\\n\")\n",
    "# out_m.close()\n",
    "# out_v.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
