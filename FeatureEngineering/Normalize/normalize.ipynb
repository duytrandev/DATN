{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, '../../FeatureEngineering/')\n",
    "import preprocessing\n",
    "preprocesser = preprocessing.Preprocesser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyvi import ViTokenizer, ViPosTagger\n",
    "\n",
    "\n",
    "# c = ViPosTagger.postagging(ViTokenizer.tokenize(u\"Trường đại học Bách Khoa Hà Nội\"))\n",
    "# for i in c:\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Data/cleaned_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_cleaned = preprocesser.fit_transform(data['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Content_cleaned_v1'] = content_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Người tiêu dùng trẻ ngày càng có xu hướng chi tiêu thông minh hơn khi biết tận dụng các nền tảng trực tuyến để \"săn\" mua được các mặt hàng chất lượng với mức giá \"hời\" từ các thương hiệu mua sắm uy tín.  Các trang thương mại điện tử, website mua sắm lớn như Shopee, Lazada, Tiki… cũng nắm bắt tâm lý này để tạo ra những \"ngày hội mua sắm\", nhằm kích thích nhu cầu tiêu dùng của khách hàng thông qua các chương trình giảm giá, săn sale… từ các thương hiệu mua sắm uy tín từ đa dạng các lĩnh vực. Có thể thấy, mua sắm trực tuyến đã dần định hình xu hướng, có nhiều tiềm năng phát triển mạnh mẽ và được đón nhận rộng rãi hơn trong thời gian sắp tới, đặc biệt là phân khúc người tiêu dùng trẻ - những người am hiểu về công nghệ và đề cao tính tiện lợi.   Nắm bắt được thị hiếu người tiêu dùng Việt, cũng như mong muốn nâng cao trải nghiệm mua sắm và thanh toán trực tuyến tiện lợi, Ngân hàng Shinhan vừa ra mắt tiện ích \"Mua sắm hoàn tiền\" trên ứng dụng SOL với ưu đãi hoàn tiền không giới hạn lên đến 35% hấp dẫn đến từ hàng trăm thương hiệu mua sắm uy tín ở đa dạng lĩnh vực.  Đặc biệt, Ngân hàng Shinhan là ngân hàng nước ngoài đầu tiên tại Việt Nam ra mắt tính năng tiện ích này.  Khách hàng sẽ nhận được ưu đãi hoàn tiền hấp dẫn lên đến 35% vào tài khoản tại Ngân hàng Shinhan, không giới hạn số lượng giao dịch và số tiền được hoàn khi mua sắm từ các thương hiệu thuộc đa dạng lĩnh vực như: Thương mại điện tử (Lazada, Tiki, Shopee,...), Lưu trú du lịch (Traveloka, Klook, Bamboo Airways,…), Ăn uống (Highland Coffee, KFC, Trung Nguyên Café Legend,…), Làm đẹp thời trang (JUNO, The Face Shop, Nike,…), Giáo dục (ELSA, ILA, Unica,…), Tài chính - Bảo hiểm (Bảo Việt, Manulife, Ví VNPAY,...) thông qua Ứng dụng Shinhan SOL Việt Nam. (*)  Tỷ lệ hoàn tiền tùy thuộc vào thương hiệu và nhóm sản phẩm, dựa trên các điều kiện và điều khoản của riêng từng thương hiệu và nhóm sản phẩm đó. Để được hoàn tiền khi mua sắm tại trang mua sắm của các thương hiệu thông qua Ứng dụng SOL, khách hàng chỉ cần thực hiện theo các bước sau: Tải ngay ứng dụng SOL tại link: https://vnsol.onelink.me/ipGX/PRCashback để trải nghiệm tiện ích \"Mua sắm hoàn tiền\" hấp dẫn và tận hưởng không gian mua sắm trực tuyến tuyệt vời ngay hôm nay! Trong trường hợp cần được hỗ trợ giải đáp các thắc mắc, Quý khách vui lòng truy cập mục \"Hỗ trợ\" tại trang \"Mua sắm hoàn tiền\" trên ứng dụng SOL, và chọn 1 trong các hình thức sau: (*) Điều kiện và điều khoản chi tiết về tiện ích \"Mua sắm hoàn tiền\" xem tại đây. Việc ra mắt tính năng \"Mua sắm hoàn tiền\" trên ứng dụng SOL minh chứng những nỗ lực của Ngân hàng Shinhan trong công cuộc đẩy mạnh số hóa, xây dựng hệ sinh thái số tiện ích, an toàn và bảo mật thông qua việc tăng cường mở rộng mạng lưới hợp tác với các đối tác uy tín, nhằm nâng cao trải nghiệm của khách hàng. Đồng thời, đáp ứng hiệu quả nhu cầu mua sắm trực tuyến ngày càng cao của khách hàng.  Vừa qua, Ngân hàng Shinhan đón nhận ba giải thưởng danh giá từ các tổ chức quốc tế uy tín, bao gồm: Giải thưởng Ngân hàng Quốc tế tốt nhất trong việc chuyển đổi số tại Việt Nam năm 2023 do Tạp chí International Business trao tặng, Giải thưởng Ngân hàng Quốc tế tốt nhất tại Việt Nam năm 2023 do Tạp chí World Economic trao tặng và Giải thưởng Ngân hàng Quốc tế tốt nhất về bán lẻ tại Việt Nam năm 2023 do Tạp chí Global Business Review trao tặng. Tất cả những giải thưởng này được xem là sự ghi nhận xứng đáng cho những nỗ lực không ngừng của Ngân hàng Shinhan trên đa phương diện và khía cạnh, nhằm tối ưu giá trị mang đến khách hàng, cũng như nâng tầm trải nghiệm tài chính trong bối cảnh chuyển đổi số đang diễn biến mạnh mẽ.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1].Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiêu_dùng trẻ xu_hướng chi_tiêu thông_minh tận_dụng nền_tảng trực_tuyến   săn   mua mặt_hàng chất_lượng giá   hời   thương_hiệu mua_sắm uy_tín   trang thương_mại điện_tử   website mua_sắm shopee   lazada   tiki   nắm_bắt tâm_lý   hội mua_sắm     kích_thích nhu_cầu tiêu_dùng khách_hàng thông_qua chương_trình giảm_giá   săn sale   thương_hiệu mua_sắm uy_tín đa_dạng lĩnh_vực     mua_sắm trực_tuyến dần định_hình xu_hướng   tiềm_năng phát_triển mạnh_mẽ đón_nhận rộng_rãi   phân khúc tiêu_dùng trẻ   am_hiểu công_nghệ đề_cao tiện_lợi   nắm_bắt thị_hiếu tiêu_dùng việt   mong_muốn nâng trải nghiệm mua_sắm thanh_toán trực_tuyến tiện_lợi   ngân_hàng shinhan ra_mắt tiện_ích   mua_sắm hoàn tiền   ứng_dụng sol ưu_đãi hoàn tiền giới_hạn   hấp_dẫn hàng trăm thương_hiệu mua_sắm uy_tín đa_dạng lĩnh_vực     ngân_hàng shinhan ngân_hàng nước_ngoài việt_nam ra_mắt tính_năng tiện_ích   khách_hàng ưu_đãi hoàn tiền hấp_dẫn   tài_khoản ngân_hàng shinhan   giới_hạn số_lượng giao_dịch tiền hoàn mua_sắm thương_hiệu đa_dạng lĩnh_vực   thương_mại điện_tử   lazada   tiki   shopee           lưu_trú du_lịch   traveloka   klook   bamboo_airways         ăn_uống   highland_coffee   kfc   trung_nguyên café_legend         làm_đẹp thời_trang   juno   the_face shop   nike         giáo_dục   elsa   ila   unica         tài_chính   bảo_hiểm   bảo việt   manulife   ví vnpay         thông_qua ứng_dụng shinhan sol việt_nam         tỷ_lệ hoàn tiền tùy thương_hiệu sản_phẩm   dựa điều_khoản thương_hiệu sản_phẩm   hoàn tiền mua_sắm trang mua_sắm thương_hiệu thông_qua ứng_dụng sol   khách_hàng   tải ứng_dụng sol link   https   vnsol onelink me ipgx prcashback trải nghiệm tiện_ích   mua_sắm hoàn tiền   hấp_dẫn tận_hưởng không_gian mua_sắm trực_tuyến tuyệt_vời hôm_nay   trường_hợp giải_đáp thắc_mắc   quý_khách vui_lòng truy_cập mục     trang   mua_sắm hoàn tiền   ứng_dụng sol   hình_thức         điều_khoản chi_tiết tiện_ích   mua_sắm hoàn tiền     ra_mắt tính_năng   mua_sắm hoàn tiền   ứng_dụng sol minh chứng nỗ_lực ngân_hàng shinhan công_cuộc đẩy_mạnh hóa   xây_dựng hệ sinh_thái tiện_ích   an_toàn bảo_mật thông_qua tăng_cường mở_rộng mạng_lưới hợp_tác đối_tác uy_tín   nâng trải nghiệm khách_hàng     đáp_ứng hiệu_quả nhu_cầu mua_sắm trực_tuyến khách_hàng     ngân_hàng shinhan đón_nhận giải_thưởng danh_giá tổ_chức quốc_tế uy_tín   bao_gồm   giải_thưởng ngân_hàng quốc_tế chuyển_đổi việt_nam tạp_chí international_business trao_tặng   giải_thưởng ngân_hàng quốc_tế việt_nam tạp_chí world economic trao_tặng giải_thưởng ngân_hàng quốc_tế bán_lẻ việt_nam tạp_chí global business_review trao_tặng   giải_thưởng ghi_nhận xứng_đáng nỗ_lực ngừng ngân_hàng shinhan đa_phương_diện khía_cạnh   tối_ưu khách_hàng   nâng tầm trải nghiệm tài_chính bối_cảnh chuyển_đổi diễn_biến mạnh_mẽ  '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1].Content_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a toy corpus\n",
    "# corpus = ['this is document one', 'this is document two', 'this is document three', 'this is document four', 'this is document five']\n",
    "\n",
    "# Create a CountVectorizer object and fit it to the corpus\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data[\"Content_cleaned_v1\"])\n",
    "\n",
    "# Get the vocabulary and document frequency (df) for each term\n",
    "vocab = vectorizer.vocabulary_\n",
    "df = X.sum(axis=0)\n",
    "\n",
    "# Calculate the max_df threshold (e.g., 0.8)\n",
    "max_df = 0.8 * len(data[\"Content\"])\n",
    "min_df = 2\n",
    "# Get the list of terms that exceed the max_df threshold\n",
    "max_df_terms = [term for term in vocab if df[0, vocab[term]] > max_df]\n",
    "min_df_terms = [term for term in vocab if df[0, vocab[term]] < min_df]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82429, 69, 148134)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min_df_terms), len(max_df_terms), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "# Example Series\n",
    "# List of words to remove\n",
    "words_to_remove = max_df_terms + min_df_terms\n",
    "\n",
    "# Remove whole words from each row\n",
    "# content_cleaned_v2 = data[\"Content_cleaned_v1\"].str.replace(r'\\b(?:{})\\b'.format('|'.join(map(re.escape, words_to_remove))), '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i, v in enumerate(words_to_remove):\n",
    "  dic[v] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_cleaned_v2 = []\n",
    "for i in content_cleaned:\n",
    "  words = i.split()\n",
    "  new_words = []\n",
    "  for word in words:\n",
    "    if word in dic:\n",
    "      continue\n",
    "    else:\n",
    "      new_words.append(word)\n",
    "  new_content = \" \".join(new_words)\n",
    "  content_cleaned_v2.append(new_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Content_cleaned_v2'] = content_cleaned_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>Content_cleaned</th>\n",
       "      <th>content_cleaned_v1</th>\n",
       "      <th>Length_content_cleaned</th>\n",
       "      <th>Content_cleaned_v1</th>\n",
       "      <th>Content_cleaned_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sao Việt ngày 29/3: NSƯT Chí Trung cùng bạn gá...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>việt     nsưt chí_trung gái đi du_lịch mỹ     ...</td>\n",
       "      <td>sao việt ngày nsưt chí_trung cùng bạn gái đi d...</td>\n",
       "      <td>21</td>\n",
       "      <td>sao việt ngày nsưt chí_trung cùng bạn gái đi d...</td>\n",
       "      <td>sao việt nsưt chí_trung bạn gái du_lịch mỹ thờ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Người tiêu dùng trẻ ngày càng có xu hướng chi ...</td>\n",
       "      <td>business</td>\n",
       "      <td>tiêu_dùng trẻ xu_hướng chi_tiêu thông_minh tận...</td>\n",
       "      <td>người tiêu_dùng trẻ ngày_càng có xu_hướng chi_...</td>\n",
       "      <td>311</td>\n",
       "      <td>người tiêu_dùng trẻ ngày_càng có xu_hướng chi_...</td>\n",
       "      <td>tiêu_dùng trẻ ngày_càng xu_hướng chi_tiêu thôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trong khuôn viên rất rộng ở khu liên hợp thể t...</td>\n",
       "      <td>sport</td>\n",
       "      <td>khuôn_viên rộng khu liên_hợp thể_thao techo mo...</td>\n",
       "      <td>trong khuôn_viên rất rộng ở khu liên_hợp thể_t...</td>\n",
       "      <td>253</td>\n",
       "      <td>trong khuôn_viên rất rộng ở khu liên_hợp thể_t...</td>\n",
       "      <td>khuôn_viên rộng ở khu liên_hợp thể_thao techo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Một trong những triệu chứng điển hình của tiểu...</td>\n",
       "      <td>health</td>\n",
       "      <td>triệu_chứng điển_hình tiểu tần_suất đi_tiểu nư...</td>\n",
       "      <td>một trong những triệu_chứng điển_hình của tiểu...</td>\n",
       "      <td>287</td>\n",
       "      <td>một trong những triệu_chứng điển_hình của tiểu...</td>\n",
       "      <td>triệu_chứng điển_hình tiểu ít tần_suất đi_tiểu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Từ ngày 27/2-2/3, Hiệp hội golf Việt Nam tổ ch...</td>\n",
       "      <td>sport</td>\n",
       "      <td>hiệp_hội golf việt_nam tổ_chức vòng_lo...</td>\n",
       "      <td>từ ngày hiệp_hội golf việt_nam tổ_chức vòng_lo...</td>\n",
       "      <td>105</td>\n",
       "      <td>từ ngày hiệp_hội golf việt_nam tổ_chức vòng_lo...</td>\n",
       "      <td>hiệp_hội golf tổ_chức vòng_loại tuyển_chọn đội...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24409</th>\n",
       "      <td>24409</td>\n",
       "      <td>Ở nội dung đôi nam nữ, Trần Ngọc Thúy Vi và Lê...</td>\n",
       "      <td>sport</td>\n",
       "      <td>nội_dung đôi nam_nữ   trần_ngọc thúy_vi lê_hoà...</td>\n",
       "      <td>ở nội_dung đôi nam_nữ trần_ngọc thúy_vi và lê_...</td>\n",
       "      <td>149</td>\n",
       "      <td>ở nội_dung đôi nam_nữ trần_ngọc thúy_vi và lê_...</td>\n",
       "      <td>ở nội_dung đôi nam_nữ trần_ngọc thúy_vi lê_hoà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24410</th>\n",
       "      <td>24410</td>\n",
       "      <td>Nguồn: Next Sports  Thiên Bình</td>\n",
       "      <td>sport</td>\n",
       "      <td>next sports thiên_bình</td>\n",
       "      <td>nguồn next sports thiên_bình</td>\n",
       "      <td>3</td>\n",
       "      <td>nguồn next sports thiên_bình</td>\n",
       "      <td>nguồn next sports thiên_bình</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24411</th>\n",
       "      <td>24411</td>\n",
       "      <td>Nhận định trận đấu giữa Arsenal vs Brighton Tr...</td>\n",
       "      <td>sport</td>\n",
       "      <td>nhận_định trận_đấu arsenal vs brighton khuôn_k...</td>\n",
       "      <td>nhận_định trận_đấu giữa arsenal vs brighton tr...</td>\n",
       "      <td>156</td>\n",
       "      <td>nhận_định trận_đấu giữa arsenal vs brighton tr...</td>\n",
       "      <td>nhận_định trận_đấu giữa arsenal vs brighton kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24412</th>\n",
       "      <td>24412</td>\n",
       "      <td>Dù giành chiến thắng trước Myanmar ở vòng bảng...</td>\n",
       "      <td>sport</td>\n",
       "      <td>giành chiến_thắng myanmar vòng bảng hlv mai_đứ...</td>\n",
       "      <td>dù giành chiến_thắng trước myanmar ở vòng bảng...</td>\n",
       "      <td>138</td>\n",
       "      <td>dù giành chiến_thắng trước myanmar ở vòng bảng...</td>\n",
       "      <td>dù giành chiến_thắng myanmar ở vòng bảng hlv m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24413</th>\n",
       "      <td>24413</td>\n",
       "      <td>Mauricio Pochettino sẽ trở lại Premier League ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>mauricio_pochettino trở_lại premier_league làm...</td>\n",
       "      <td>mauricio_pochettino sẽ trở_lại premier_league ...</td>\n",
       "      <td>123</td>\n",
       "      <td>mauricio_pochettino sẽ trở_lại premier_league ...</td>\n",
       "      <td>mauricio_pochettino trở_lại premier_league làm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24414 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            Content  \\\n",
       "0               0  Sao Việt ngày 29/3: NSƯT Chí Trung cùng bạn gá...   \n",
       "1               1  Người tiêu dùng trẻ ngày càng có xu hướng chi ...   \n",
       "2               2  Trong khuôn viên rất rộng ở khu liên hợp thể t...   \n",
       "3               3  Một trong những triệu chứng điển hình của tiểu...   \n",
       "4               4  Từ ngày 27/2-2/3, Hiệp hội golf Việt Nam tổ ch...   \n",
       "...           ...                                                ...   \n",
       "24409       24409  Ở nội dung đôi nam nữ, Trần Ngọc Thúy Vi và Lê...   \n",
       "24410       24410                    Nguồn: Next Sports  Thiên Bình    \n",
       "24411       24411  Nhận định trận đấu giữa Arsenal vs Brighton Tr...   \n",
       "24412       24412  Dù giành chiến thắng trước Myanmar ở vòng bảng...   \n",
       "24413       24413  Mauricio Pochettino sẽ trở lại Premier League ...   \n",
       "\n",
       "               Label                                    Content_cleaned  \\\n",
       "0      entertainment  việt     nsưt chí_trung gái đi du_lịch mỹ     ...   \n",
       "1           business  tiêu_dùng trẻ xu_hướng chi_tiêu thông_minh tận...   \n",
       "2              sport  khuôn_viên rộng khu liên_hợp thể_thao techo mo...   \n",
       "3             health  triệu_chứng điển_hình tiểu tần_suất đi_tiểu nư...   \n",
       "4              sport          hiệp_hội golf việt_nam tổ_chức vòng_lo...   \n",
       "...              ...                                                ...   \n",
       "24409          sport  nội_dung đôi nam_nữ   trần_ngọc thúy_vi lê_hoà...   \n",
       "24410          sport                             next sports thiên_bình   \n",
       "24411          sport  nhận_định trận_đấu arsenal vs brighton khuôn_k...   \n",
       "24412          sport  giành chiến_thắng myanmar vòng bảng hlv mai_đứ...   \n",
       "24413          sport  mauricio_pochettino trở_lại premier_league làm...   \n",
       "\n",
       "                                      content_cleaned_v1  \\\n",
       "0      sao việt ngày nsưt chí_trung cùng bạn gái đi d...   \n",
       "1      người tiêu_dùng trẻ ngày_càng có xu_hướng chi_...   \n",
       "2      trong khuôn_viên rất rộng ở khu liên_hợp thể_t...   \n",
       "3      một trong những triệu_chứng điển_hình của tiểu...   \n",
       "4      từ ngày hiệp_hội golf việt_nam tổ_chức vòng_lo...   \n",
       "...                                                  ...   \n",
       "24409  ở nội_dung đôi nam_nữ trần_ngọc thúy_vi và lê_...   \n",
       "24410                       nguồn next sports thiên_bình   \n",
       "24411  nhận_định trận_đấu giữa arsenal vs brighton tr...   \n",
       "24412  dù giành chiến_thắng trước myanmar ở vòng bảng...   \n",
       "24413  mauricio_pochettino sẽ trở_lại premier_league ...   \n",
       "\n",
       "       Length_content_cleaned  \\\n",
       "0                          21   \n",
       "1                         311   \n",
       "2                         253   \n",
       "3                         287   \n",
       "4                         105   \n",
       "...                       ...   \n",
       "24409                     149   \n",
       "24410                       3   \n",
       "24411                     156   \n",
       "24412                     138   \n",
       "24413                     123   \n",
       "\n",
       "                                      Content_cleaned_v1  \\\n",
       "0      sao việt ngày nsưt chí_trung cùng bạn gái đi d...   \n",
       "1      người tiêu_dùng trẻ ngày_càng có xu_hướng chi_...   \n",
       "2      trong khuôn_viên rất rộng ở khu liên_hợp thể_t...   \n",
       "3      một trong những triệu_chứng điển_hình của tiểu...   \n",
       "4      từ ngày hiệp_hội golf việt_nam tổ_chức vòng_lo...   \n",
       "...                                                  ...   \n",
       "24409  ở nội_dung đôi nam_nữ trần_ngọc thúy_vi và lê_...   \n",
       "24410                       nguồn next sports thiên_bình   \n",
       "24411  nhận_định trận_đấu giữa arsenal vs brighton tr...   \n",
       "24412  dù giành chiến_thắng trước myanmar ở vòng bảng...   \n",
       "24413  mauricio_pochettino sẽ trở_lại premier_league ...   \n",
       "\n",
       "                                      Content_cleaned_v2  \n",
       "0      sao việt nsưt chí_trung bạn gái du_lịch mỹ thờ...  \n",
       "1      tiêu_dùng trẻ ngày_càng xu_hướng chi_tiêu thôn...  \n",
       "2      khuôn_viên rộng ở khu liên_hợp thể_thao techo ...  \n",
       "3      triệu_chứng điển_hình tiểu ít tần_suất đi_tiểu...  \n",
       "4      hiệp_hội golf tổ_chức vòng_loại tuyển_chọn đội...  \n",
       "...                                                  ...  \n",
       "24409  ở nội_dung đôi nam_nữ trần_ngọc thúy_vi lê_hoà...  \n",
       "24410                       nguồn next sports thiên_bình  \n",
       "24411  nhận_định trận_đấu giữa arsenal vs brighton kh...  \n",
       "24412  dù giành chiến_thắng myanmar ở vòng bảng hlv m...  \n",
       "24413  mauricio_pochettino trở_lại premier_league làm...  \n",
       "\n",
       "[24414 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../../Data/cleaned_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test = content_test.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in content_test.iloc[2].split():\n",
    "  if i != \" \":\n",
    "    arr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data.iloc[:20].Length_content_cleaned, label='Array 1')\n",
    "plt.plot(len_test, label='Array 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stop = data.iloc[1].Content_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_stop.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Content_cleaned\"] = preprocesser.fit_transform(data[\"Content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Length_content_cleaned\"] = data[\"Content_cleaned\"].apply(lambda doc: len(str(doc).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_removed = [\"việt_nam\", \"trường\", \"đồng\", \"giá\", \"hai\"]\n",
    "# for doc in data[\"Content_clean2\"]:\n",
    "#   new_doc = \" \".join([word for word in doc.split() if word not in word_removed])\n",
    "#   data[\"Content_clean2\"] = data[\"Content_clean2\"].replace(doc, new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Length_content_cleaned\"] > 1]\n",
    "data = data[data[\"Length_content_cleaned\"] < 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.rename(columns={\"Contents\": \"Content\", \"Labels\": \"Label\"})\n",
    "data = data.dropna(subset=[\"Content_cleaned\"])\n",
    "data = data.drop_duplicates(subset=[\"Content_cleaned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=42)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"Content\", \"Label\", \"Content_cleaned\", \"Length_content_cleaned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, df_education, df_sport])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../../Data/cleaned_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport = data[data[\"Label\"] == 'sport']\n",
    "# df_health = data[data[\"Label\"] == 'health']\n",
    "# df_business = data[data[\"Label\"] == 'business']\n",
    "# df_entertainment = data[data[\"Label\"] == 'entertainment']\n",
    "# df_politics = data[data[\"Label\"] == 'politics']\n",
    "df_education = data[data[\"Label\"] == 'education']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = pd.concat([df_education, pd.read_csv(\"../../Data/educationcleaned_v1.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data[[\"Content\", \"Label\", \"Content_cleaned\", 'content_cleaned_v1', \"Length_content_cleaned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../../Data/cleaned_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [df_business, df_education, df_entertainment, df_health, df_politics, df_sport]:\n",
    "  d.to_csv(\"../../Data/\"+d[\"Label\"].iloc[0]+\"cleaned_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in data[\"Label\"].unique():\n",
    "  # calculate the IQR\n",
    "  q1 = data[data[\"Label\"] == label]['Length_content_cleaned'].quantile(0.25)\n",
    "  q3 = data[data[\"Label\"] == label]['Length_content_cleaned'].quantile(0.75)\n",
    "  iqr = q3 - q1\n",
    "\n",
    "  # calculate the lower and upper bounds for outlier detection\n",
    "  lower_bound = 10\n",
    "  upper_bound = q3 + 1.5*iqr\n",
    "\n",
    "  # remove outliers\n",
    "  data[data[\"Label\"] == label] = data[data[\"Label\"] == label][(data['Length_content_cleaned'] >= lower_bound) & (data['Length_content_cleaned'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../../Data/merged_thapcam_cleaned_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = pd.read_csv('/Users/DuyHome/HocTap/DATN/Data/clean_v1.csv')\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.concat([v1, data])\n",
    "check = check.drop_duplicates(subset=[\"Content_cleaned\"])\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_vietnamnet_cleand2 = \"../../Data/Dataset/vietnamnet/clean_v2.csv\"\n",
    "v2 = pd.read_csv(path_to_data_vietnamnet_cleand2)\n",
    "v3 = pd.concat([v1, v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3.to_csv(\"../../Data/Dataset/clean_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = pd.read_csv(path_to_save_data_v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
